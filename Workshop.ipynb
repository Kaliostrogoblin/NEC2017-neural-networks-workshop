{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.layers import Flatten\n",
    "from keras.models import model_from_json\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# specify a number of output classes\n",
    "# MNIST data has ten categories, each means particular digit\n",
    "N_CLASSES  = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess MNIST data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data splitted in two sets - train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 60000\n",
      "Test size:  10000\n"
     ]
    }
   ],
   "source": [
    "(X_train,y_train),(X_test,y_test) = mnist.load_data() \n",
    " \n",
    "print('Train size: {:5}'.format(len(X_train)))\n",
    "print('Test size: {:6}'.format(len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescale original image data to be in range [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_max before rescaling - 255\n",
      "X_max after rescaling  - 1.0\n"
     ]
    }
   ],
   "source": [
    "# before rescaling\n",
    "print('X_max before rescaling - {}'.format(X_train.max()))\n",
    "\n",
    "X_train_rescaled = X_train / 255.\n",
    "X_test_rescaled  = X_test / 255.\n",
    "# after rescaling\n",
    "print('X_max after rescaling  - {}'.format(X_train_rescaled.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show one training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8ANJEX4gKcIPJEX4gaQIP5DU/wOIhnLCVSTquwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22f0e598ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# randomly choose index of the image to show\n",
    "i = np.random.randint(0, 9999)\n",
    "\n",
    "plt.imshow(X_test_rescaled[i])\n",
    "plt.title(y_test[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Represent categorical labels as one-hot vectors\n",
    "\n",
    "For example, imagine that we have ten classes of data samples. So for the label equals to 3 one-hot vector would be:\n",
    "```python\n",
    "    0 0 0 1 0 0 0 0 0 0 \n",
    "```\n",
    "This transformation is nessesary for computing categorical cross-entropy loss:\n",
    "$$L = -\\sum_{i}^N{L_i \\log{(S_i)}},$$\n",
    "Where $S$ is output from Softmax Layer and $L$ is Labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_categorical = to_categorical(y_train, num_classes=N_CLASSES)\n",
    "y_test_categorical  = to_categorical(y_test, num_classes=N_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build neural networks models\n",
    "\n",
    "We will construct three different types of NNs:\n",
    "- shallow network with one hidden layer;\n",
    "- deep convolutional neural network (CNN);\n",
    "- recurrent neural network (RNN);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shallow Network with one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "SimpleNN = Sequential() # keras class of sequential model allows us to build NN by adding new layers \n",
    "\n",
    "# for the first layer (our hidden layer) of sequential model we should specify inputshape\n",
    "# ordinary NNs operates on 1D representations of data\n",
    "# so the translation of each 28x28 image is vector size of 784\n",
    "SimpleNN.add(Dense(1024,                   # number of output nodes\n",
    "                   input_shape=(784,),     # for the first layer of sequential model we shouls specify the input shape\n",
    "                   activation='sigmoid',   # activation function\n",
    "                   kernel_initializer='random_uniform',  # weights initializer\n",
    "                   bias_initializer='zeros'))            # bias initializer\n",
    "SimpleNN.add(Dense(N_CLASSES, activation='softmax', kernel_initializer='random_uniform', bias_initializer='zeros'))\n",
    "\n",
    "# compiling model\n",
    "SimpleNN.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# print our model\n",
    "SimpleNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              2360320   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 2,422,666\n",
      "Trainable params: 2,422,666\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ConvNN = Sequential()\n",
    "\n",
    "# 32 means the number of filters, features\n",
    "# (3,3) is tuple represents the filters sizes, e.g. each filter is a square with size 3x3\n",
    "# padding='same' - we add zeros across each of edges of the input sample\n",
    "# (28, 28, 1) - input shape, where 1 is a single gray channel (we may have RGB images with shape = 28,28,3)\n",
    "ConvNN.add(Conv2D(32, (5,5), input_shape=(28, 28, 1), activation='relu'))\n",
    "ConvNN.add(MaxPool2D(pool_size=(2,2)))\n",
    "ConvNN.add(Conv2D(64, (5,5), padding='same', activation='relu'))\n",
    "ConvNN.add(MaxPool2D(pool_size=(2,2)))\n",
    "ConvNN.add(Flatten()) # operation that flattens input tensor\n",
    "ConvNN.add(Dense(1024, activation='relu'))\n",
    "ConvNN.add(Dense(N_CLASSES, activation='softmax'))\n",
    "\n",
    "# compile model\n",
    "ConvNN.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# print model\n",
    "ConvNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 64)                17856     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 18,506\n",
      "Trainable params: 18,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "RNN = Sequential()\n",
    "\n",
    "# we extract 64 features from GRU neurons\n",
    "# each image presented as 28 sequences, i.e., rows of pixels\n",
    "RNN.add(GRU(64, input_shape=(28, 28)))\n",
    "RNN.add(Dense(N_CLASSES, activation='softmax'))\n",
    "\n",
    "# compile model\n",
    "RNN.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "# print model\n",
    "RNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train all three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shallow Network\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 35s - loss: 0.0771 - acc: 0.9762 - val_loss: 0.0868 - val_acc: 0.9733\n",
      "Epoch 2/3\n",
      "15328/60000 [======>.......................] - ETA: 26s - loss: 0.0535 - acc: 0.9838\n",
      "Training was interrupted!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # rescale input data to pass to simpleNN\n",
    "    X_train_rescaled = X_train_rescaled.reshape((len(X_train_rescaled), 28*28))\n",
    "    X_test_rescaled  = X_test_rescaled.reshape((len(X_test_rescaled), 28*28))\n",
    "    # fit shallow network\n",
    "    print('Train Shallow Network')\n",
    "    SimpleNN.fit(X_train_rescaled, y_train_categorical, epochs=3, validation_data=(X_test_rescaled, y_test_categorical))\n",
    "\n",
    "    # rescale input data to pass to convNN\n",
    "    X_train_rescaled = X_train_rescaled.reshape((len(X_train_rescaled), 28, 28, 1))\n",
    "    X_test_rescaled  = X_test_rescaled.reshape((len(X_test_rescaled), 28, 28, 1))\n",
    "    # fit convolutional network\n",
    "    print('Train Convolutional Network')\n",
    "    ConvNN.fit(X_train_rescaled, y_train_categorical, epochs=3, validation_data=(X_test_rescaled, y_test_categorical))\n",
    "\n",
    "    # rescale input data to pass to RNN\n",
    "    X_train_rescaled = X_train_rescaled.reshape((len(X_train_rescaled), 28, 28))\n",
    "    X_test_rescaled  = X_test_rescaled.reshape((len(X_test_rescaled), 28, 28))\n",
    "    # fit recurrent neural network\n",
    "    print('Train Recurrent Neural')\n",
    "    RNN.fit(X_train_rescaled, y_train_categorical, epochs=3, validation_data=(X_test_rescaled, y_test_categorical))\n",
    "except KeyboardInterrupt:\n",
    "    print('\\nTraining was interrupted!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restoring models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow network with one hidden layer\n",
    "# load model\n",
    "with open('data/SimpleNN.json', 'r') as f:\n",
    "    SimpleNN = model_from_json(f.read())\n",
    "#load trainable weights\n",
    "SimpleNN.load_weights('data/SimpleNN.h5')\n",
    "\n",
    "# convolutional neural network\n",
    "with open('data/ConvNN.json', 'r') as f:\n",
    "    ConvNN = model_from_json(f.read())\n",
    "ConvNN.load_weights('data/ConvNN.h5')\n",
    "\n",
    "# recurrent neural network\n",
    "with open('data/RNN.json', 'r') as f:\n",
    "    RNN = model_from_json(f.read())\n",
    "RNN.load_weights('data/RNN.h5')\n",
    "\n",
    "### Compiling all three models\n",
    "SimpleNN.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "ConvNN.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "RNN.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test efficiencies\n",
      " 9920/10000 [============================>.] - ETA: 0s\tSimpleNN: 0.9686\n",
      " 9984/10000 [============================>.] - ETA: 0s\tConvNN: 0.992\n",
      " 9984/10000 [============================>.] - ETA: 0s\tRNN: 0.9834\n"
     ]
    }
   ],
   "source": [
    "print('Test efficiencies')\n",
    "\n",
    "#Shallow network\n",
    "X_test_rescaled  = X_test_rescaled.reshape((len(X_test_rescaled), 28*28))\n",
    "print('\\tSimpleNN: {}'.format(SimpleNN.evaluate(X_test_rescaled, y_test_categorical)[1]))\n",
    "\n",
    "#Convolutional Network\n",
    "X_test_rescaled  = X_test_rescaled.reshape((len(X_test_rescaled), 28, 28, 1))\n",
    "print('\\tConvNN: {}'.format(ConvNN.evaluate(X_test_rescaled, y_test_categorical)[1]))\n",
    "\n",
    "#Recurrent Network\n",
    "X_test_rescaled  = X_test_rescaled.reshape((len(X_test_rescaled), 28, 28))\n",
    "print('\\tRNN: {}'.format(RNN.evaluate(X_test_rescaled, y_test_categorical)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shallow network with one hidden layer\n",
    "with open('data/SimpleNN.json', 'w') as f:\n",
    "    f.write(SimpleNN.to_json())        # save model's graph\n",
    "SimpleNN.save_weights('data/SimpleNN.h5')   # save model's weights\n",
    "\n",
    "# convolutional neural network\n",
    "with open('data/ConvNN.json', 'w') as f:\n",
    "    f.write(ConvNN.to_json())\n",
    "ConvNN.save_weights('data/ConvNN.h5')\n",
    "\n",
    "# recurrent neural network\n",
    "with open('data/RNN.json', 'w') as f:\n",
    "    f.write(RNN.to_json())\n",
    "RNN.save_weights('data/RNN.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
