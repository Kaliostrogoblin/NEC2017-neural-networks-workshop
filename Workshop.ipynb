{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.layers import Flatten\n",
    "from keras.models import model_from_json\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# specify a number of output classes\n",
    "# MNIST data has ten categories, each means particular digit\n",
    "N_CLASSES  = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess MNIST data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data splitted in two sets - train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 60000\n",
      "Test size:  10000\n"
     ]
    }
   ],
   "source": [
    "(X_train,y_train),(X_test,y_test) = mnist.load_data() \n",
    " \n",
    "print('Train size: {:5}'.format(len(X_train)))\n",
    "print('Test size: {:6}'.format(len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescale original image data to be in range [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_max before rescaling - 255\n",
      "X_max after rescaling  - 1.0\n"
     ]
    }
   ],
   "source": [
    "# before rescaling\n",
    "print('X_max before rescaling - {}'.format(X_train.max()))\n",
    "\n",
    "X_train_rescaled = X_train / 255.\n",
    "X_test_rescaled  = X_test / 255.\n",
    "# after rescaling\n",
    "print('X_max after rescaling  - {}'.format(X_train_rescaled.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show one training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHwiK8ANBEX4gKMIPBEX4gaD+F0pxFlt3rzgNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b547e81128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# randomly choose index of the image to show\n",
    "i = np.random.randint(0, 9999)\n",
    "\n",
    "plt.imshow(X_test_rescaled[i])\n",
    "plt.title(y_test[i])\n",
    "plt.gray()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Represent categorical labels as one-hot vectors\n",
    "\n",
    "For example, imagine that we have ten classes of data samples. So for the label equals to 3 one-hot vector would be:\n",
    "```python\n",
    "    0 0 0 1 0 0 0 0 0 0 \n",
    "```\n",
    "This transformation is nessesary for computing categorical cross-entropy loss:\n",
    "$$L = -\\sum_{i}^N{L_i \\log{(S_i)}},$$\n",
    "Where $S$ is output from Softmax Layer and $L$ is Labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_categorical = to_categorical(y_train, num_classes=N_CLASSES)\n",
    "y_test_categorical  = to_categorical(y_test, num_classes=N_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build neural networks models\n",
    "\n",
    "We will construct three different types of NNs:\n",
    "- shallow network with one hidden layer;\n",
    "- deep convolutional neural network (CNN);\n",
    "- recurrent neural network (RNN);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shallow Network with one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "SimpleNN = Sequential() # keras class of sequential model allows us to build NN by adding new layers \n",
    "\n",
    "# for the first layer (our hidden layer) of sequential model we should specify inputshape\n",
    "# ordinary NNs operates on 1D representations of data\n",
    "# so the translation of each 28x28 image is vector size of 784\n",
    "SimpleNN.add(Dense(1024,                   # number of output nodes\n",
    "                   input_shape=(784,),     # for the first layer of sequential model we shouls specify the input shape\n",
    "                   activation='sigmoid',   # activation function\n",
    "                   kernel_initializer='random_uniform',  # weights initializer\n",
    "                   bias_initializer='zeros'))            # bias initializer\n",
    "SimpleNN.add(Dense(N_CLASSES, activation='softmax', kernel_initializer='random_uniform', bias_initializer='zeros'))\n",
    "\n",
    "# compiling model\n",
    "SimpleNN.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# print our model\n",
    "SimpleNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              2360320   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 2,422,666\n",
      "Trainable params: 2,422,666\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ConvNN = Sequential()\n",
    "\n",
    "# 32 means the number of filters, features\n",
    "# (3,3) is tuple represents the filters sizes, e.g. each filter is a square with size 3x3\n",
    "# padding='same' - we add zeros across each of edges of the input sample\n",
    "# (28, 28, 1) - input shape, where 1 is a single gray channel (we may have RGB images with shape = 28,28,3)\n",
    "ConvNN.add(Conv2D(32, (5,5), input_shape=(28, 28, 1), activation='relu'))\n",
    "ConvNN.add(MaxPool2D(pool_size=(2,2)))\n",
    "ConvNN.add(Conv2D(64, (5,5), padding='same', activation='relu'))\n",
    "ConvNN.add(MaxPool2D(pool_size=(2,2)))\n",
    "ConvNN.add(Flatten()) # operation that flattens input tensor\n",
    "ConvNN.add(Dense(1024, activation='relu'))\n",
    "ConvNN.add(Dense(N_CLASSES, activation='softmax'))\n",
    "\n",
    "# compile model\n",
    "ConvNN.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# print model\n",
    "ConvNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 64)                17856     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 18,506\n",
      "Trainable params: 18,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "RNN = Sequential()\n",
    "\n",
    "# we extract 64 features from GRU neurons\n",
    "# each image presented as 28 sequences, i.e., rows of pixels\n",
    "RNN.add(GRU(64, input_shape=(28, 28)))\n",
    "RNN.add(Dense(N_CLASSES, activation='softmax'))\n",
    "\n",
    "# compile model\n",
    "RNN.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "# print model\n",
    "RNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train all three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shallow Network\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 35s - loss: 0.0771 - acc: 0.9762 - val_loss: 0.0868 - val_acc: 0.9733\n",
      "Epoch 2/3\n",
      "15328/60000 [======>.......................] - ETA: 26s - loss: 0.0535 - acc: 0.9838\n",
      "Training was interrupted!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # rescale input data to pass to simpleNN\n",
    "    X_train_rescaled = X_train_rescaled.reshape((len(X_train_rescaled), 28*28))\n",
    "    X_test_rescaled  = X_test_rescaled.reshape((len(X_test_rescaled), 28*28))\n",
    "    # fit shallow network\n",
    "    print('Train Shallow Network')\n",
    "    SimpleNN.fit(X_train_rescaled, y_train_categorical, epochs=3, validation_data=(X_test_rescaled, y_test_categorical))\n",
    "\n",
    "    # rescale input data to pass to convNN\n",
    "    X_train_rescaled = X_train_rescaled.reshape((len(X_train_rescaled), 28, 28, 1))\n",
    "    X_test_rescaled  = X_test_rescaled.reshape((len(X_test_rescaled), 28, 28, 1))\n",
    "    # fit convolutional network\n",
    "    print('Train Convolutional Network')\n",
    "    ConvNN.fit(X_train_rescaled, y_train_categorical, epochs=3, validation_data=(X_test_rescaled, y_test_categorical))\n",
    "\n",
    "    # rescale input data to pass to RNN\n",
    "    X_train_rescaled = X_train_rescaled.reshape((len(X_train_rescaled), 28, 28))\n",
    "    X_test_rescaled  = X_test_rescaled.reshape((len(X_test_rescaled), 28, 28))\n",
    "    # fit recurrent neural network\n",
    "    print('Train Recurrent Neural')\n",
    "    RNN.fit(X_train_rescaled, y_train_categorical, epochs=3, validation_data=(X_test_rescaled, y_test_categorical))\n",
    "except KeyboardInterrupt:\n",
    "    print('\\nTraining was interrupted!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restoring models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shallow network with one hidden layer\n",
    "# load model\n",
    "with open('data/SimpleNN.json', 'r') as f:\n",
    "    SimpleNN = model_from_json(f.read())\n",
    "#load trainable weights\n",
    "SimpleNN.load_weights('data/SimpleNN.h5')\n",
    "\n",
    "# convolutional neural network\n",
    "with open('data/ConvNN.json', 'r') as f:\n",
    "    ConvNN = model_from_json(f.read())\n",
    "ConvNN.load_weights('data/ConvNN.h5')\n",
    "\n",
    "# recurrent neural network\n",
    "with open('data/RNN.json', 'r') as f:\n",
    "    RNN = model_from_json(f.read())\n",
    "RNN.load_weights('data/RNN.h5')\n",
    "\n",
    "### Compiling all three models\n",
    "SimpleNN.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "ConvNN.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "RNN.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test efficiencies\n",
      " 9920/10000 [============================>.] - ETA: 0s\tSimpleNN: 0.9686\n",
      " 9984/10000 [============================>.] - ETA: 0s\tConvNN: 0.992\n",
      " 9984/10000 [============================>.] - ETA: 0s\tRNN: 0.9834\n"
     ]
    }
   ],
   "source": [
    "print('Test efficiencies')\n",
    "\n",
    "#Shallow network\n",
    "X_test_rescaled  = X_test_rescaled.reshape((len(X_test_rescaled), 28*28))\n",
    "print('\\tSimpleNN: {}'.format(SimpleNN.evaluate(X_test_rescaled, y_test_categorical)[1]))\n",
    "\n",
    "#Convolutional Network\n",
    "X_test_rescaled  = X_test_rescaled.reshape((len(X_test_rescaled), 28, 28, 1))\n",
    "print('\\tConvNN: {}'.format(ConvNN.evaluate(X_test_rescaled, y_test_categorical)[1]))\n",
    "\n",
    "#Recurrent Network\n",
    "X_test_rescaled  = X_test_rescaled.reshape((len(X_test_rescaled), 28, 28))\n",
    "print('\\tRNN: {}'.format(RNN.evaluate(X_test_rescaled, y_test_categorical)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shallow network with one hidden layer\n",
    "with open('data/SimpleNN.json', 'w') as f:\n",
    "    f.write(SimpleNN.to_json())        # save model's graph\n",
    "SimpleNN.save_weights('data/SimpleNN.h5')   # save model's weights\n",
    "\n",
    "# convolutional neural network\n",
    "with open('data/ConvNN.json', 'w') as f:\n",
    "    f.write(ConvNN.to_json())\n",
    "ConvNN.save_weights('data/ConvNN.h5')\n",
    "\n",
    "# recurrent neural network\n",
    "with open('data/RNN.json', 'w') as f:\n",
    "    f.write(RNN.to_json())\n",
    "RNN.save_weights('data/RNN.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Github link - https://github.com/Kaliostrogoblin/NEC2017-neural-networks-workshop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
